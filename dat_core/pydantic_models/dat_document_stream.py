# generated by datamodel-codegen:
#   filename:  DatDocumentStream.yml
#   timestamp: 2024-04-18T06:49:10+00:00

from __future__ import annotations

from typing import Any, Dict, List, Optional, Union

from pydantic import BaseModel, Field
from dat_core.pydantic_models.base import EnumWithStr


class ReadSyncMode(EnumWithStr):
    FULL_REFRESH = 'FULL_REFRESH'
    INCREMENTAL = 'INCREMENTAL'


class WriteSyncMode(EnumWithStr):
    APPEND = 'APPEND'
    UPSERT = 'UPSERT'
    REPLACE = 'REPLACE'


class SplitByHtmlHeaderExtraConfig(BaseModel):
    headers_to_split_on: Optional[List[str]] = Field(
        ['h2', 'h3'],
        description='list of headers we want to track mapped to (arbitrary) keys for metadata. Allowed header values: h1, h2, h3, h4, h5, h6',
    )


class SplitByHtmlHeaderSettings(BaseModel):
    strategy: Optional[str] = 'SPLIT_BY_HTML_HEADER'
    config: Optional[SplitByHtmlHeaderExtraConfig] = None


class SplitByCharacterExtraConfig(BaseModel):
    separator: Optional[str] = '\\n\\n'


class SplitByCharacterSettings(BaseModel):
    strategy: Optional[str] = 'SPLIT_BY_CHARACTER'
    config: Optional[SplitByCharacterExtraConfig] = None


class SplitCodeExtraConfig(BaseModel):
    separators: Optional[List] = ['\\nclass ', '\\ndef ']


class SplitCodeSettings(BaseModel):
    strategy: Optional[str] = 'SPLIT_CODE'
    config: Optional[SplitCodeExtraConfig] = None


class SplitByMarkdownSettings(BaseModel):
    strategy: Optional[str] = 'SPLIT_BY_MARKDOWN'
    config: Optional[Dict[str, Any]] = {}


class SplitJsonRecursivelySettings(BaseModel):
    strategy: Optional[str] = 'SPLIT_JSON_RECURSIVELY'
    config: Optional[Dict[str, Any]] = {}


class SplitByCharacterRecursiverlyConfig(BaseModel):
    separators: Optional[List] = ['\n\n', '\n', ' ', '']


class SplitByCharacterRecursiverlySettings(BaseModel):
    strategy: Optional[str] = 'SPLIT_BY_CHARACTER_RECURSIVELY'
    config: Optional[SplitByCharacterRecursiverlyConfig] = None


class SplitByTokensSettings(BaseModel):
    strategy: Optional[str] = 'SPLIT_BY_TOKENS'
    config: Optional[SplitByCharacterRecursiverlyConfig] = None


class Advanced(BaseModel):
    splitter_settings: Optional[
        Union[
            SplitByHtmlHeaderSettings,
            SplitByCharacterSettings,
            SplitCodeSettings,
            SplitByMarkdownSettings,
            SplitJsonRecursivelySettings,
            SplitByCharacterRecursiverlySettings,
            SplitByTokensSettings,
        ]
    ] = None


class DatDocumentStream(BaseModel):
    class Config:
        extra = 'allow'

    name: str = Field(..., description='The name of the document stream.')
    namespace: Optional[str] = Field(
        None, description='The namespace the data is associated with.'
    )
    json_schema: Optional[Dict[str, Any]] = Field(
        None, description='The JSON schema for the document stream.'
    )
    read_sync_mode: Optional[ReadSyncMode] = Field(
        'INCREMENTAL',
        description='A list of supported sync modes for the stream while reading.',
    )
    write_sync_mode: Optional[WriteSyncMode] = Field(
        'APPEND',
        description='A list of supported sync modes for the stream while writing.',
    )
    cursor_field: Optional[str] = Field(
        None,
        description='The path to the field used to determine if a record is new or modified.\nREQUIRED for INCREMENTAL sync mode.',
    )
    advanced: Optional[Advanced] = Field(
        None, description='Additional optional settings'
    )
