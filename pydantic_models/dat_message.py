# generated by datamodel-codegen:
#   filename:  DatMessage.yml
#   timestamp: 2023-12-01T11:09:15+00:00

from __future__ import annotations

from enum import Enum
from typing import Any, Dict, List, Optional

from pydantic import AnyUrl, BaseModel, Extra, Field
from dat_catalog import DatCatalog
from dat_log_message import DatLogMessage


class Type(Enum):
    RECORD = 'RECORD'
    STATE = 'STATE'
    LOG = 'LOG'
    SPEC = 'SPEC'
    CONNECTION_STATUS = 'CONNECTION_STATUS'
    CATALOG = 'CATALOG'
    TRACE = 'TRACE'


class ConnectorSpecification(BaseModel):
    class Config:
        extra = Extra.allow

    protocol_version: Optional[str] = Field(
        None,
        description='the Vectorize Protocol version supported by the connector. Protocol versioning uses SemVer.',
    )
    documentationUrl: Optional[AnyUrl] = None
    changelogUrl: Optional[AnyUrl] = None
    connectionSpecification: Dict[str, Any] = Field(
        ...,
        description='ConnectorDefinition specific blob. Must be a valid JSON string.',
    )
    supportsIncremental: Optional[bool] = Field(
        None, description='If the connector supports incremental mode or not.'
    )
    supported_destination_sync_modes: Optional[List[Any]] = Field(
        None, description='List of destination sync modes supported by the connector'
    )


class Status(Enum):
    SUCCEEDED = 'SUCCEEDED'
    FAILED = 'FAILED'


class DatConnectionStatus(BaseModel):
    class Config:
        extra = Extra.allow

    status: Status
    message: Optional[str] = None


class SyncMode(Enum):
    full_refresh = 'full_refresh'
    incremental = 'incremental'


class DocumentStream(BaseModel):
    name: str
    dir_uris: Optional[List[str]] = None
    sync_mode: SyncMode


class Data(BaseModel):
    document_chunk: Optional[Dict[str, Any]] = Field(
        None, description='document chunks emitted by source'
    )


class DatDocumentMessage(BaseModel):
    class Config:
        extra = Extra.allow

    namespace: Optional[str] = Field(
        None, description='namespace the data is associated with'
    )
    stream: str = Field(..., description='stream the data is associated with')
    data: Data = Field(..., description='record data')
    emitted_at: int = Field(
        ...,
        description='when the data was emitted from the source. epoch in millisecond.',
    )


class StreamDescriptor(BaseModel):
    class Config:
        extra = Extra.allow

    name: str
    namespace: Optional[str] = None


class StreamState(BaseModel):
    class Config:
        extra = Extra.allow

    data: Dict[str, Any] = Field(..., description='the state data')


class Stream(BaseModel):
    class Config:
        extra = Extra.allow

    stream_descriptor: StreamDescriptor = Field(
        ...,
        description='A stream descriptor contains all information required to identify a Stream',
    )
    stream_state: StreamState


class DatStateMessage(BaseModel):
    class Config:
        extra = Extra.allow

    stream: Optional[Stream] = None


class DatMessage(BaseModel):
    class Config:
        extra = 'allow'

    type: Type = Field(..., description='Message type')
    log: Optional[DatLogMessage] = Field(
        None,
        description='log message: any kind of logging you want the platform to know about.',
    )
    spec: Optional[ConnectorSpecification] = None
    connectionStatus: Optional[DatConnectionStatus] = None
    catalog: Optional[DatCatalog] = Field(
        None, description='catalog message: the catalog'
    )
    record: Optional[DatDocumentMessage] = Field(
        None, description='record message: the record'
    )
    state: Optional[DatStateMessage] = Field(
        None,
        description='schema message: the state. Must be the last message produced. The platform uses this information',
    )
